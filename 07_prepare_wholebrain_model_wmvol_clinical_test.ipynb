{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35bec88-db34-4d2f-8a69-cfc9a7e3aa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/preclineu/hansav/.conda/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pcntoolkit as ptk \n",
    "from pcntoolkit.util.utils import create_design_matrix\n",
    "from pcntoolkit.dataio.fileio import save as ptksave\n",
    "from pcntoolkit.dataio.fileio import load as ptkload\n",
    "\n",
    "# globals\n",
    "root_dir = '/project_cephfs/3022017.06/ENIGMA_ANX/'\n",
    "\n",
    "###  CHANGE DEPENDING ON Z-STAT OR SCALED EFFECT  ###\n",
    "proc_dir = os.path.join(root_dir,'Z_stat/')\n",
    "#proc_dir = os.path.join(root_dir,'Scaled_effect/')\n",
    "\n",
    "data_dir = os.path.join(proc_dir,'data/')\n",
    "mask_nii = ('/opt/fmriprep/templateflow/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_res-02_desc-brain_mask.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53ada3d-e7a0-4180-bd95-6654e54a4c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading covariate data ...\n",
      "581\n"
     ]
    }
   ],
   "source": [
    "# load covariates\n",
    "print('loading covariate data ...')\n",
    "df_dem = pd.read_csv(os.path.join(data_dir,'clinical_te.csv'))\n",
    " \n",
    "df_tr = pd.read_csv(os.path.join(data_dir,'metadata_tr.csv'))\n",
    "       \n",
    "\n",
    "# use the whole dataset\n",
    "te = np.ones(df_dem.shape[0]) == 1\n",
    "\n",
    "#df_tr = df_dem.iloc[tr]\n",
    "#df_tr.to_csv(os.path.join(proc_dir,'metadata_cl.csv'))\n",
    "df_te = df_dem.iloc[te]\n",
    "df_te.to_csv(os.path.join(proc_dir,'metadata_cl.csv'))\n",
    "\n",
    "print(len(df_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5ee564-ecc7-4d3f-a366-f54dd030b332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring covariates ...\n"
     ]
    }
   ],
   "source": [
    "# Configure covariates\n",
    "\n",
    "# design matrix parameters\n",
    "xmin = 4 #REAL: 9 # boundaries for ages of participants +/- 5\n",
    "xmax = 71 #REAL:66\n",
    "cols_cov = [\"Age\", \n",
    "            \"Sex\",\n",
    "            \"MRI\", \n",
    "            \"Instructions\",\n",
    "            \"Precond_number_trials\",\n",
    "            \"Multiple_CSplus\", \n",
    "            \"Multiple_CSminus\",\n",
    "            \"CS_type_neutral_faces\",\n",
    "            \"CS_type_neutral_pictures\",\n",
    "            \"CS_type_neutral_male_avatar\",\n",
    "            \"CS_type_snakes_spiders\",\n",
    "            \"CS_type_gabor_patch\",\n",
    "            \"CS_type_animal_tool\",\n",
    "            \"CS_type_affective_faces_pictures\",\n",
    "            \"CS_type_humanoic_characters\",\n",
    "            \"Number_CSplus_cond\",\n",
    "            \"Number_CSminus_cond\",\n",
    "            \"Reinforcing_rate\",\n",
    "            \"US_type_electric_shock\", \n",
    "            \"US_type_auditory\", \n",
    "            \"US_type_visceral\",\n",
    "            \"US_type_thermal\", \n",
    "            \"Average_ITI\", \n",
    "            \"Average_ISI\",\n",
    "            \"Potential_US_confound\"]\n",
    "\n",
    "site_ids =  sorted(set(df_tr['Group_Dataset'].to_list())) #39 different sites\n",
    "\n",
    "print('configuring covariates ...')\n",
    "# X_tr = create_design_matrix(df_tr[cols_cov], site_ids = df_tr['dataset'],\n",
    "#                             basis = 'bspline', xmin = xmin, xmax = xmax)\n",
    "#print(X_tr)\n",
    "X_te = create_design_matrix(df_te[cols_cov], site_ids = df_te['Group_Dataset'], all_sites=site_ids,\n",
    "                            basis = 'bspline', xmin = xmin, xmax = xmax)\n",
    "\n",
    "#cov_file_tr = os.path.join(proc_dir, 'cov_bspline_cl.txt')\n",
    "cov_file_te = os.path.join(proc_dir, 'cov_bspline_cl.txt')\n",
    "#ptk.dataio.fileio.save(X_tr, cov_file_tr)\n",
    "ptksave(X_te, cov_file_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e6f8a5-881a-4992-a94d-a7dbf77862de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wholebrain response data ...\n",
      "loading study 0 [ /project_cephfs/3022017.06/ENIGMA_ANX/Z_stat/data/ENIGMA_FC_cl_1.nii.gz ] ...\n",
      "(291, 235840)\n",
      "loading study 1 [ /project_cephfs/3022017.06/ENIGMA_ANX/Z_stat/data/ENIGMA_FC_cl_2.nii.gz ] ...\n",
      "(290, 235840)\n",
      "(581, 235840)\n"
     ]
    }
   ],
   "source": [
    "# configure response data\n",
    "\n",
    "data_nii = []\n",
    "data_nii.append(os.path.join(data_dir, 'ENIGMA_FC_cl_1.nii.gz'))\n",
    "data_nii.append(os.path.join(data_dir, 'ENIGMA_FC_cl_2.nii.gz'))\n",
    "\n",
    "# load the response data as nifti\n",
    "print('loading wholebrain response data ...') \n",
    "for i, f in enumerate(data_nii):\n",
    "    print('loading study', i, '[', f, '] ...')\n",
    "    if i == 0:\n",
    "        x = ptkload(f, mask=mask_nii, vol=False).T\n",
    "        print(x.shape)\n",
    "        #x = ptk.dataio.fileio.load_nifti(f, mask=None, vol=False).T #without the  vol=False\n",
    "    else: \n",
    "        x1 = ptkload(f, mask=mask_nii, vol=False).T\n",
    "        print(x1.shape)\n",
    "        x = np.concatenate((x, ptk.dataio.fileio.load(f, mask=mask_nii, vol=False).T))\n",
    "        print(x.shape)\n",
    "        #x =  np.concatenate((x, ptk.dataio.fileio.load_nifti(f, mask=None, vol=False).T)) #without the  vol=False\n",
    "\n",
    "# HACK: some of the voxels in the mask are all zero in this dataset, which \n",
    "# causes problems. for these voxels, just impute with the mean of neighbouring\n",
    "# voxels\n",
    "bad_vox = np.where(np.bitwise_or(~np.isfinite(x[te,:]).any(axis=0), np.var(x[te,:], axis=0) == 0))[0]\n",
    "for b in bad_vox:\n",
    "    x[:,b] = (x[:,b-1] + x[:,b-2]) /2 + np.random.normal(scale=0.1, size=x.shape[0])\n",
    "\n",
    "# and write out as pkl\n",
    "#resp_file_tr = os.path.join(proc_dir,'resp_cl.pkl')\n",
    "resp_file_te = os.path.join(proc_dir,'resp_cl.pkl')\n",
    "#ptk.dataio.fileio.save(x[tr,:], resp_file_tr)\n",
    "ptksave(x[te,:], resp_file_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595677f-e719-45a0-8d90-01f5e226a4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
