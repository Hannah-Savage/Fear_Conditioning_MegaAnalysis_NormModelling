{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adfe10cc-aedf-4c4b-b323-f89e003f5955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/preclineu/hansav/.conda/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pcntoolkit as ptk \n",
    "from pcntoolkit.util.utils import create_design_matrix\n",
    "\n",
    "# globals\n",
    "root_dir = '/project_cephfs/3022017.06/ENIGMA_ANX/Z_stat/'\n",
    "data_dir = os.path.join(root_dir,'data/')\n",
    "mask_nii = ('/opt/fmriprep/templateflow/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_res-02_desc-brain_mask.nii.gz')\n",
    "\n",
    "proc_dir = os.path.join(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f1e08de-3fe9-4b13-93f3-8fa1fd58ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# load  training and test\n",
    "##############################\n",
    "df_tr = pd.read_csv(os.path.join(data_dir,'metadata_tr.csv'))\n",
    "df_te = pd.read_csv(os.path.join(data_dir,'metadata_te.csv'))\n",
    "\n",
    "#Make sure that all the columns are numerical not string\n",
    "#columns_to_convert = ['Healthy_or_patient', 'Age', 'Sex', 'Trauma_exposed', 'MRI', 'Instructions', \n",
    "#                      'Precond_number_trials', 'Multiple_CSplus', 'Multiple_CSminus', \n",
    "#                      'CS_type_neutral_faces', 'CS_type_neutral_pictures', 'CS_type_neutral_male_avatar', \n",
    "#                      'CS_type_snakes_spiders', 'CS_type_gabor_patch', 'CS_type_animal_tool', \n",
    "#                      'CS_type_affective_faces_pictures', 'CS_type_humanoic_characters', \n",
    "#                      'Number_CSplus_cond', 'Number_CSminus_cond', 'Reinforcement_Rate',\n",
    "#                      'US_type_electric_shock', 'US_type_auditory', 'US_type_visceral', \n",
    "#                      'US_type_thermal', 'Average_ITI', 'Average_ISI'] #'Reinforcing_rate'\n",
    "\n",
    "# Count NaN values before conversion\n",
    "#nan_before = df_tr[columns_to_convert].isna().sum()\n",
    "#nan_before = df_te[columns_to_convert].isna().sum()\n",
    "\n",
    "# Convert the specified columns to numeric, coercing errors to NaN\n",
    "#df_tr[columns_to_convert] = df_tr[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "#df_te[columns_to_convert] = df_te[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Count NaN values after conversion\n",
    "#nan_after = df_tr[columns_to_convert].isna().sum()\n",
    "#nan_after = df_te[columns_to_convert].isna().sum()\n",
    "\n",
    "# Calculate the number of NaN values introduced\n",
    "#nan_introduced = nan_after - nan_before\n",
    "#nan_introduced = nan_after - nan_before\n",
    "\n",
    "# Display the results\n",
    "#print(\"NaN values introduced in each column:\")\n",
    "#print(nan_introduced)\n",
    "\n",
    "#print(df_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22708386-95f9-4c3c-97ab-cd7afc89ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring covariates ...\n",
      "[[1.00000000e+00 1.80000000e+01 1.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 2.20000000e+01 1.00000000e+00 ... 2.71388832e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 2.20000000e+01 0.00000000e+00 ... 2.71388832e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.00000000e+00 5.20000000e+01 1.00000000e+00 ... 5.96393921e-01\n",
      "  1.71738245e-01 0.00000000e+00]\n",
      " [1.00000000e+00 2.90000000e+01 1.00000000e+00 ... 2.47303073e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 4.40000000e+01 1.00000000e+00 ... 4.16598819e-01\n",
      "  1.74536943e-02 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Configure covariates\n",
    "######################\n",
    "# design matrix parameters\n",
    "xmin = 3 #REAL: 8 # boundaries for ages of participants +/- 5\n",
    "xmax = 71 #REAL:66\n",
    "cols_cov = [\"Age\", \n",
    "            \"Sex\",\n",
    "            \"MRI\", \n",
    "            \"Instructions\",\n",
    "            \"Precond_number_trials\",\n",
    "            \"Multiple_CSplus\", \n",
    "            \"Multiple_CSminus\",\n",
    "            \"CS_type_neutral_faces\",\n",
    "            \"CS_type_neutral_pictures\",\n",
    "            \"CS_type_neutral_male_avatar\",\n",
    "            \"CS_type_snakes_spiders\",\n",
    "            \"CS_type_gabor_patch\",\n",
    "            \"CS_type_animal_tool\",\n",
    "            \"CS_type_affective_faces_pictures\",\n",
    "            \"CS_type_humanoic_characters\",\n",
    "            \"Number_CSplus_cond\",\n",
    "            \"Number_CSminus_cond\",\n",
    "            \"Reinforcing_rate\",\n",
    "            \"US_type_electric_shock\", \n",
    "            \"US_type_auditory\", \n",
    "            \"US_type_visceral\",\n",
    "            \"US_type_thermal\", \n",
    "            \"Average_ITI\", \n",
    "            \"Average_ISI\",\n",
    "            \"Potential_US_confound\"] \n",
    "site_ids =  sorted(set(df_tr['Group_Dataset'].to_list())) \n",
    "\n",
    "print('configuring covariates ...')\n",
    "X_tr = create_design_matrix(df_tr[cols_cov], site_ids = df_tr['Group_Dataset'],\n",
    "                            basis = 'bspline', xmin = xmin, xmax = xmax)\n",
    "print(X_tr)\n",
    "X_te = create_design_matrix(df_te[cols_cov], site_ids = df_te['Group_Dataset'], all_sites=site_ids,\n",
    "                            basis = 'bspline', xmin = xmin, xmax = xmax)\n",
    "\n",
    "cov_file_tr = os.path.join(proc_dir, 'cov_bspline_tr.txt')\n",
    "cov_file_te = os.path.join(proc_dir, 'cov_bspline_te.txt')\n",
    "ptk.dataio.fileio.save(X_tr, cov_file_tr)\n",
    "ptk.dataio.fileio.save(X_te, cov_file_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c03e9b-f5dd-4598-b5cc-b43b1d5524bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wholebrain response data ...\n",
      "loading study 0 [ /project_cephfs/3022017.06/ENIGMA_ANX/Z_stat/data/ENIGMA_FC_tr_1.nii.gz ] ...\n",
      "(447, 235840)\n",
      "loading study 1 [ /project_cephfs/3022017.06/ENIGMA_ANX/Z_stat/data/ENIGMA_FC_tr_2.nii.gz ] ...\n",
      "(447, 235840)\n",
      "(894, 235840)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# configure response data\n",
    "#########################\n",
    "## load the response data as nifti - Train\n",
    "data_nii_tr = []\n",
    "data_nii_tr.append(os.path.join(data_dir, 'ENIGMA_FC_tr_1.nii.gz')) #concatenate the 4D nii files\n",
    "data_nii_tr.append(os.path.join(data_dir, 'ENIGMA_FC_tr_2.nii.gz')) #concatenate the 4D nii files\n",
    "\n",
    "# load the response data as nifti\n",
    "print('loading wholebrain response data ...') \n",
    "for i, f in enumerate(data_nii_tr):\n",
    "    print('loading study', i, '[', f, '] ...')\n",
    "    if i == 0:\n",
    "        x_tr = ptk.dataio.fileio.load(f, mask=mask_nii, vol=False).T\n",
    "        print(x_tr.shape)\n",
    "        #x = ptk.dataio.fileio.load_nifti(f, mask=None, vol=False).T #without the  vol=False\n",
    "    else: \n",
    "        x_tr1 = ptk.dataio.fileio.load(f, mask=mask_nii, vol=False).T\n",
    "        print(x_tr1.shape)\n",
    "        x_tr = np.concatenate((x_tr, ptk.dataio.fileio.load(f, mask=mask_nii, vol=False).T))\n",
    "        print(x_tr.shape)\n",
    "        #x =  np.concatenate((x, ptk.dataio.fileio.load_nifti(f, mask=None, vol=False).T)) #without the  vol=False\n",
    "# and write out as pkl\n",
    "resp_file_tr = os.path.join(proc_dir,'resp_tr.pkl')\n",
    "ptk.dataio.fileio.save(x_tr, resp_file_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e04cd4-8231-42b2-9c7b-00a5ff7fb866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wholebrain response data ...\n",
      "loading study 0 [ /project_cephfs/3022017.06/ENIGMA_ANX/Z_stat/data/ENIGMA_FC_te_1.nii.gz ] ...\n",
      "(323, 235840)\n",
      "loading study 1 [ /project_cephfs/3022017.06/ENIGMA_ANX/Z_stat/data/ENIGMA_FC_te_2.nii.gz ] ...\n",
      "(323, 235840)\n",
      "(646, 235840)\n"
     ]
    }
   ],
   "source": [
    "## load the response data as nifti - Test\n",
    "data_nii_te = []\n",
    "data_nii_te.append(os.path.join(data_dir, 'ENIGMA_FC_te_1.nii.gz'))\n",
    "data_nii_te.append(os.path.join(data_dir, 'ENIGMA_FC_te_2.nii.gz'))\n",
    "\n",
    "# load the response data as nifti\n",
    "print('loading wholebrain response data ...') \n",
    "for i, f in enumerate(data_nii_te):\n",
    "    print('loading study', i, '[', f, '] ...')\n",
    "    if i == 0:\n",
    "        x_te = ptk.dataio.fileio.load(f, mask=mask_nii, vol=False).T\n",
    "        print(x_te.shape)\n",
    "        #x = ptk.dataio.fileio.load_nifti(f, mask=None, vol=False).T #without the  vol=False\n",
    "    else: \n",
    "        x_te1 = ptk.dataio.fileio.load(f, mask=mask_nii, vol=False).T\n",
    "        print(x_te1.shape)\n",
    "        x_te = np.concatenate((x_te, ptk.dataio.fileio.load(f, mask=mask_nii, vol=False).T))\n",
    "        print(x_te.shape)\n",
    "# and write out as pkl\n",
    "resp_file_te = os.path.join(proc_dir,'resp_te.pkl')\n",
    "ptk.dataio.fileio.save(x_te, resp_file_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d6533-f22e-44d9-b591-6ff0acbe5d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
